# This is configuration for standard experiment. Please refer to config.py for more details.
name: ''
description: >
    Final version
n_sample: 64
resolution: 256
classes:
- 'ref'
- 'target'

ADA:
  enabled: true
  target: 0.6  # set 0 to fix prob.
  p: 0.0
  interval: 4
  kimg: 500
  # KWARGS:
  #   aniso: 0
  #   xfrac: 0
  #   brightness: 0
  #   contrast: 0
  #   lumaflip: 0
  #   hue: 0
  #   saturation: 0

DATASET:
  name: FFHQ256
  root: '~/data/FFHQ'
  sources:
    - 'images256x256-cropface'
    - 'images256x256'
  # num_items: 1000  # Manually set #imgs before x-flip
  xflip: true
  num_workers: 4
  pin_memory: true

MODEL:
  z_dim: 512
  w_dim: 512
  mode: 'joint'

  MAPPING:
    num_layers: 8
    # embed_dim: 512
    # layer_dim: 512
    lrmul: 0.01
  
  SYNTHESIS:
    img_channels: 3
    bottom_res: 4
    channel_base: 32768

  DISCRIMINATOR:
    img_channels: [3, 3]
    c_dim: 0
    branch_res: 32
    top_res: 4
    channel_base: 32768
    mbstd_group_size: 8

TRAIN:
  iteration: 390625
  batch_gpu: 8
  lrate: 0.0025
  use_mix_loss: false
  R1:
    every: 16
    gamma: 0.5  # float
  PPL:
    every: 8
    gain: 2
    bs_shrink: 2
  style_mixing_prob: 0.9
  ema: 20
  CKPT:
    path: ''
    every: 6250
    max_keep: -1  # -1 to keep all
  SAMPLE:
    every: 3125

EVAL:
  metrics: 'fid'
  batch_gpu: 8
  FID:
    every: 3125
    batch_gpu: 64
    n_sample: 50000
    inception_cache: ''
  KID:
    every: 3125
    batch_gpu: 64
    n_sample: 50000
    inception_cache: ''

