# This is configuration for standard experiment. Please refer to config.py for more details.
name: 'FaceHuman-KD-attention'
description: >
    Default configuration for synthesis of face & human.
    Apply maxpooling to face features(query), Separate Attention Network from Generator
n_sample: 64
resolution: 256
classes:
- 'face'
- 'human'

ADA:
  enabled: true
  target: 0.6  # set 0 to fix prob.
  p: 0.0
  interval: 4
  kimg: 500
  # KWARGS:

DATASET:
  name: DeepFashion
  roots:
    - '~/data/deepfashion'
  sources:
    - 'align_1.2'  # directory of face image
    - 'images'     # subdirectory of human image
  xflip: true
  num_workers: 0
  pin_memory: true

MODEL:
  z_dim: 512
  w_dim: 512
  mode: 'joint'
  freeze_teacher: false
  teacher_weight: ''

  MAPPING:
    num_layers: 8
    # embed_dim: 512
    # layer_dim: 512
    lrmul: 0.01
  
  SYNTHESIS:
    img_channels: 3
    bottom_res: 4
    channel_base: 16384
    pose_encoder_kwargs:
      name: HeatmapEncoder
      max_channels: 512
      heatmap_size: 256
      in_channels: 17

  ATTENTION:
    resolutions: [4, 8, 16, 32, 64, 128, 256]
    feature_types: 'relu'

  DISCRIMINATOR:
    img_channels: [3, 3]
    c_dim: 0
    branch_res: 32
    top_res: 4
    channel_base: 16384


TRAIN:
  iteration: 5
  batch_gpu: 8
  lrate: 0.002
  lrate_atten: 0.002
  R1:
    every: 16
    gamma: 10
  PPL:
    every: 8
    gain: 2
    bs_shrink: 2
  style_mixing_prob: 0.0
  CKPT:
    path: ''
    every: 5
    max_keep: -1
  SAMPLE:
    every: 5

EVAL:
  metrics: 'fid'
  batch_gpu: 8
  FID:
    every: 5
    batch_gpu: 64
    n_sample: 50000
    inception_cache: '/tmp/inception_cache.pkl'

